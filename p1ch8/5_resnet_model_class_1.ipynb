{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-25T08:34:54.989555100Z",
     "start_time": "2023-06-25T08:34:52.156436300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# 加载数据集并进行预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "trainset = datasets.CIFAR10(root=data_path, train=True,\n",
    "                            download=True, transform=transform_train)\n",
    "testset = datasets.CIFAR10(root=data_path, train=False,\n",
    "                           download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# 定义残差块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 定义残差网络\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda')\n",
    "# 加载数据集\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T08:34:56.663512Z",
     "start_time": "2023-06-25T08:34:54.990555200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.5857, Train Acc: 0.4045\n",
      "Epoch: 2, Train Loss: 1.0881, Train Acc: 0.6088\n",
      "Epoch: 3, Train Loss: 0.9048, Train Acc: 0.6774\n",
      "Epoch: 4, Train Loss: 0.7712, Train Acc: 0.7294\n",
      "Epoch: 5, Train Loss: 0.6819, Train Acc: 0.7627\n",
      "Epoch: 6, Train Loss: 0.6178, Train Acc: 0.7852\n",
      "Epoch: 7, Train Loss: 0.5803, Train Acc: 0.8004\n",
      "Epoch: 8, Train Loss: 0.5458, Train Acc: 0.8100\n",
      "Epoch: 9, Train Loss: 0.5170, Train Acc: 0.8213\n",
      "Epoch: 10, Train Loss: 0.5001, Train Acc: 0.8273\n",
      "Epoch: 11, Train Loss: 0.4794, Train Acc: 0.8345\n",
      "Epoch: 12, Train Loss: 0.4599, Train Acc: 0.8396\n",
      "Epoch: 13, Train Loss: 0.4466, Train Acc: 0.8459\n",
      "Epoch: 14, Train Loss: 0.4363, Train Acc: 0.8475\n",
      "Epoch: 15, Train Loss: 0.4289, Train Acc: 0.8521\n",
      "Epoch: 16, Train Loss: 0.4150, Train Acc: 0.8555\n",
      "Epoch: 17, Train Loss: 0.4008, Train Acc: 0.8619\n",
      "Epoch: 18, Train Loss: 0.3986, Train Acc: 0.8607\n",
      "Epoch: 19, Train Loss: 0.3887, Train Acc: 0.8639\n",
      "Epoch: 20, Train Loss: 0.3831, Train Acc: 0.8668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#定义模型、损失函数和优化器\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "#训练模型\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "    print('Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch+1, train_loss, train_acc))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T08:37:38.922957600Z",
     "start_time": "2023-06-25T08:34:56.666512200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 0.0000, Train `Acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估模型\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {}, Train Loss: {:.4f}, Train `Acc: {:.4f}'.format(epoch+1, train_loss, train_acc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T08:37:42.263024800Z",
     "start_time": "2023-06-25T08:37:38.925957700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-25 16:40:07.128368 开始运算\n",
      "Accuracy train: 0.86\n",
      "Accuracy val: 0.82\n",
      "2023-06-25 16:40:23.117013 结束运算\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs.to(device))\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.to(device).shape[0]  # <3>\n",
    "                correct += int((predicted == labels.to(device)).sum())  # <4>\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "print(datetime.datetime.now(), '开始运算')\n",
    "validate(model, train_loader, val_loader)\n",
    "print(datetime.datetime.now(), '结束运算')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T08:40:23.133013400Z",
     "start_time": "2023-06-25T08:40:07.129367700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
