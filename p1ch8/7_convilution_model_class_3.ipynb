{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.307\n",
      "[1,   400] loss: 2.289\n",
      "[1,   600] loss: 2.165\n",
      "[1,   800] loss: 2.193\n",
      "[1,  1000] loss: 2.130\n",
      "[1,  1200] loss: 2.042\n",
      "[1,  1400] loss: 2.030\n",
      "[1,  1600] loss: 2.011\n",
      "[1,  1800] loss: 2.003\n",
      "[1,  2000] loss: 2.079\n",
      "[1,  2200] loss: 2.082\n",
      "[1,  2400] loss: 2.019\n",
      "[1,  2600] loss: 1.947\n",
      "[1,  2800] loss: 1.976\n",
      "[1,  3000] loss: 2.035\n",
      "[1,  3200] loss: 1.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x107a62160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xuzhao/Desktop/ml/dlwpt-code/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/xuzhao/Desktop/ml/dlwpt-code/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 67\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainloader, \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m     66\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m---> 67\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m net(inputs)\n\u001B[1;32m     69\u001B[0m     pred \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "File \u001B[0;32m~/Desktop/ml/dlwpt-code/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:267\u001B[0m, in \u001B[0;36mOptimizer.zero_grad\u001B[0;34m(self, set_to_none)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m foreach:\n\u001B[1;32m    266\u001B[0m     per_device_and_dtype_grads \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28;01mlambda\u001B[39;00m: defaultdict(\u001B[38;5;28mlist\u001B[39m))\n\u001B[0;32m--> 267\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_zero_grad_profile_name):\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    269\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "File \u001B[0;32m~/Desktop/ml/dlwpt-code/venv/lib/python3.9/site-packages/torch/autograd/profiler.py:488\u001B[0m, in \u001B[0;36mrecord_function.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_record_function_enter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/ml/dlwpt-code/venv/lib/python3.9/site-packages/torch/_ops.py:442\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter  # 导入 tensorboard 所需使用的包\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 定义LeNet-5模型\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 加载CIFAR10数据集\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2)\n",
    "train_len=len(trainset)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "logdir = './log'\n",
    "\n",
    "\n",
    "writer = SummaryWriter(log_dir=logdir)\n",
    "# 初始化LeNet-5模型和优化器\n",
    "net = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    total_accurate=0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        pred = outputs.squeeze()\n",
    "        a = np.array(pred.data)\n",
    "\n",
    "        # 对模型的输出进行 softmax 计算\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        # 将真实标签转换为 one-hot 编码\n",
    "        one_hot_labels = torch.zeros(outputs.size()).scatter_(1, labels.unsqueeze(1), 1)\n",
    "        # 计算交叉熵损失\n",
    "        loss_s = -torch.sum(one_hot_labels * torch.log(probs), dim=1)\n",
    "        loss_m = torch.mean(loss_s)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_zero = loss_s - loss\n",
    "        # print(loss_zero)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        accurate=((pred>0.5)==labels).sum().item()\n",
    "        total_accurate+=accurate\n",
    "        # 在 epoch 循环中\n",
    "        avg_acc=total_accurate/train_len\n",
    "        writer.add_scalar(\"train_loss\", loss, epoch)  # 在每次计算完 loss 后添加\n",
    "        # writer.add_scalar(\"val_acc\", val_avg_acc, epoch)\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# 测试模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "# 循环结束后\n",
    "writer.close()\n",
    "#  tensorboard --logdir ./p1ch8/log 运行相应web应用，读取相应log文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
